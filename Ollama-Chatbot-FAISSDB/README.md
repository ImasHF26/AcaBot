# ğŸ¤– EduLLM Chatbot

Bienvenue dans **EduLLM Chatbot** ! Ce chatbot Python fonctionne localement, sâ€™appuie sur lâ€™API Ollama Local (`http://localhost:11434/api/generate`) et le modÃ¨le multimodal **gemma3:4b** pour offrir une assistance acadÃ©mique rapide, fiable et hors-ligne.

---

## ğŸŒŸ FonctionnalitÃ©s

- **ğŸ¡ ExÃ©cution Locale**  
  Tout se passe sur votre machine : aucune connexion internet ou API externe requise, garantissant confidentialitÃ© et accÃ¨s ininterrompu.

- **ğŸ¤– Chat IA**  
  Profitez de rÃ©ponses intelligentes, contextuelles et adaptÃ©es Ã  vos besoins Ã©ducatifs.

- **ğŸ’» GÃ©nÃ©ration de Contenu**  
  CrÃ©ez des cours complets, des quiz stimulants et des rÃ©sumÃ©s concis de documents pÃ©dagogiques.

- **âš¡ LÃ©ger et Rapide**  
  Utilise le modÃ¨le efficace **gemma3:4b** pour des performances optimales sans compromis sur la qualitÃ©.

- **ğŸ§  RAG AvancÃ© (Retrieval-Augmented Generation)**  
  - **Embedding** : IntÃ©gration avec `BAAI/bge-base-en-v1.5` pour des embeddings robustes et une comprÃ©hension sÃ©mantique prÃ©cise.  
  - **DÃ©coupage & Recouvrement** : DÃ©coupe intelligente des documents en segments avec recouvrement pour prÃ©server le contexte.  
  - **Base de Vecteurs** : Utilisation de **FaissDB** pour un stockage et une recherche rapide des informations pertinentes.  
  - **SimilaritÃ© Cosinus** : Recherche des informations les plus proches sÃ©mantiquement.  
  - **Reranking** : Raffinement des rÃ©sultats pour ne garder que les plus pertinents et cohÃ©rents.  
  - **GÃ©nÃ©ration de RÃ©ponse** : SynthÃ¨se claire, concise et prÃ©cise Ã  partir des segments retrouvÃ©s.

- **ğŸš€ Backend FastAPI**  
  Construit avec **FastAPI** pour une API robuste, performante et facile Ã  utiliser.

---

## ğŸ“‹ Prise en Main

Suivez ces Ã©tapes pour installer et lancer le chatbot :

### 1ï¸âƒ£ Cloner le DÃ©pÃ´t

```bash
git clone https://github.com/ImasHF26/EduLLM.git
cd EduLLM
```

### 2ï¸âƒ£ Installer les dÃ©pendances
Assurez-vous dâ€™avoir Python 3.11 ou plus. CrÃ©ez un environnement virtuel et installez les dÃ©pendances :

```bash
python -m venv .venv
.venv\Scripts\activate  # Sur Windows
pip install -r requirements.txt
```

### 3ï¸âƒ£ VÃ©rifier que lâ€™API locale fonctionne ğŸ–¥ï¸
Le chatbot sâ€™appuie sur une API locale pour gÃ©nÃ©rer les rÃ©ponses. VÃ©rifiez que lâ€™API Ollama fonctionne Ã  lâ€™adresse http://localhost:11434/api/generate.

ModÃ¨le utilisÃ© : gemma3:4b  
Pourquoi ce modÃ¨le ? Il offre un bon compromis entre performance, rapiditÃ© et prÃ©cision, idÃ©al pour des conversations Ã©ducatives et la gÃ©nÃ©ration de contenu.

Si lâ€™API nâ€™est pas dÃ©marrÃ©e, rÃ©fÃ©rez-vous Ã  la documentation officielle dâ€™Ollama pour configurer le serveur local et tÃ©lÃ©charger le modÃ¨le gemma3:4b.

### 4ï¸âƒ£ Lancer le chatbot ğŸš€
Une fois les dÃ©pendances installÃ©es et lâ€™API locale dÃ©marrÃ©e, lancez le chatbot :

```bash
uvicorn api.main:app --reload
```

Ouvrez votre navigateur et rendez-vous Ã  lâ€™adresse indiquÃ©e par Uvicorn (gÃ©nÃ©ralement http://127.0.0.1:8000).

### ğŸ’¬ Exemples dâ€™utilisation
Commencez Ã  discuter ! Par exemple, vous pouvez demander :

- "Qu'est ce qu'un perceptron ?"
- "Donne-moi une introduction au DevOps."
- "CrÃ©e un quiz sur l'apprentissage automatique."
- "RÃ©sume le concept de la rÃ©gression linÃ©aire."

---

## ğŸ“Œ TÃ¢ches principales du projet

- Installation et configuration de lâ€™environnement Python et des dÃ©pendances
- Mise en place et vÃ©rification de lâ€™API Ollama et du modÃ¨le gemma3:4b
- Lancement du backend FastAPI
- DÃ©veloppement et maintenance des fonctionnalitÃ©s principales (chat, gÃ©nÃ©ration de contenu, RAG, etc.)
- Tests et validation du fonctionnement du chatbot
- Documentation et amÃ©lioration continue

---

## ğŸ¤ Contribution
Les contributions sont les bienvenues ! ğŸ› ï¸

Si vous souhaitez contribuer, veuillez forker le dÃ©pÃ´t, crÃ©er une branche pour vos fonctionnalitÃ©s ou corrections, puis soumettre une pull request. Merci dâ€™aider Ã  amÃ©liorer EduLLM !